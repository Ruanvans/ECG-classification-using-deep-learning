{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mitbih_models.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "N2lNYfnQLfqA",
        "93shh5bCLwMh",
        "LBETglRbL5IO",
        "taHKs5UmNX0d",
        "YnuhUyXMPzeg",
        "fLrEcRF3Q2lB"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMGXnyXkzqdy7kEbAGw1QSb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ruanvans/ECG-classification-using-deep-learning/blob/master/mitbih_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2lNYfnQLfqA",
        "colab_type": "text"
      },
      "source": [
        "# **Importation of necessary libraries and tools**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8tgi_i9Woj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PkhIXQsY9EV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import keras \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Reshape, Dense, Activation, Flatten, Convolution1D, Dropout, MaxPooling1D, GlobalAveragePooling1D, AveragePooling1D\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.utils import resample, shuffle \n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from keras.optimizers import rmsprop\n",
        "from sklearn.metrics import roc_curve, auc ,precision_score, recall_score, confusion_matrix\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "import itertools\n",
        "from itertools import cycle \n",
        "import random\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers import LSTM,Bidirectional, GRU\n",
        "from keras import optimizers,regularizers\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from scipy import interp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93shh5bCLwMh",
        "colab_type": "text"
      },
      "source": [
        "# **Helper methods to visualize results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6eTfFW-ZBL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "   \n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGyDxnAqZE3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_evalutation(history, test, y_test, model):\n",
        "    score = model.evaluate((test),y_test)\n",
        "    print(\"Model Accuracy: %.2f%%\" % (score[1]*100))\n",
        "\n",
        "    plt.figure(figsize=(15,5))\n",
        "\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "    # Plot training & validation loss values\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper right')\n",
        "\n",
        "    plt.suptitle(\"Model Accuracy and Model Loss\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj7UIe8SZIYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def roc_curve_evaluation(y,y_pred, y_test):\n",
        "\n",
        "    y = label_binarize(y, classes=[0, 1])\n",
        "    n_classes = 2\n",
        "\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    for i in range(n_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.ravel())\n",
        "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "\n",
        "    # Then interpolate all ROC curves at this points\n",
        "    mean_tpr = np.zeros_like(all_fpr)\n",
        "    for i in range(n_classes):\n",
        "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "    mean_tpr /= n_classes\n",
        "\n",
        "    fpr[\"macro\"] = all_fpr\n",
        "    tpr[\"macro\"] = mean_tpr\n",
        "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "    lw = 2\n",
        "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "            label='micro-average ROC curve (area = {0:0.2f})'\n",
        "                  ''.format(roc_auc[\"micro\"]),\n",
        "            color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "            label='macro-average ROC curve (area = {0:0.2f})'\n",
        "                  ''.format(roc_auc[\"macro\"]),\n",
        "            color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "    for i, color in zip(range(n_classes), colors):\n",
        "        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
        "                label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "                ''.format(i, roc_auc[i]))\n",
        "\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBETglRbL5IO",
        "colab_type": "text"
      },
      "source": [
        "# **Data preparation and preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKTv3FuzMHf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importation of datasets\n",
        "df_mitbih_train = pd.read_csv('mitbih_train.csv', header=None)\n",
        "df_mitbih_test = pd.read_csv('mitbih_test.csv', header=None)\n",
        "\n",
        "#concatenation of the normal and abnormal datasets \n",
        "frames = [df_ptb1, df_ptb2]\n",
        "df_ptb3 = pd.concat(frames) \n",
        "#Does a value count of the newly made concatenated dataset\n",
        "df_ptb3[187] = df_ptb3[187].astype(int)\n",
        "equilibre = df_ptb3[187].value_counts()\n",
        "# Resampling Dataset\n",
        "df_1 = df_ptb3[df_ptb3[187] == 1]\n",
        "df_0 =(df_ptb3[df_ptb3[187] == 0]).sample(n=4000,random_state=42)\n",
        "\n",
        "df_1_upsample=resample(df_1,replace=True,n_samples=4000,random_state=123)\n",
        "train_df=pd.concat([df_0,df_1_upsample])\n",
        "#shuffle method used here to ensure that models are correctly trained and tested\n",
        "train_df= shuffle(train_df)\n",
        "#Value count on the resampled dataset\n",
        "train_df[187].value_counts()\n",
        "\n",
        "resampled = train_df[187].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taHKs5UmNX0d",
        "colab_type": "text"
      },
      "source": [
        "# **Basic neural net to establish a baseline accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn5veSzDNoY1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1 = Sequential()\n",
        "model_1.add(Dense(100, input_dim=187, activation='relu'))\n",
        "model_1.add(Dense(100, activation='relu'))\n",
        "model_1.add(Dense(90, activation='relu' ))\n",
        "model_1.add(Dense(70, activation='relu'))\n",
        "model_1.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "print(model_1.summary())\n",
        "model_1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeS-YulsNxMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_loss', patience=2)]\n",
        "\n",
        "history = model_1.fit(X_train, y_train, validation_data=(X_test, y_test), callbacks=callbacks ,epochs=100, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xd8iC7IaNxHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = X_test\n",
        "model = model_1\n",
        "model_evalutation(history, test, y_test, model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsJAEWz8Nwjl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model_1.predict(X_test, batch_size=1000)\n",
        "print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1)))\n",
        "\n",
        "# Compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "np.set_printoptions(precision=2)\n",
        "# Plot non-normalized confusion matrix\n",
        "plt.figure(figsize=(10, 10))\n",
        "plot_confusion_matrix(cnf_matrix, classes=['1','0'],\n",
        "                      title='Confusion matrix, without normalization')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBSdKMoAN9JN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = y\n",
        "y_pred = model_1.predict(X_test, batch_size=1000)\n",
        "y_test = y_test\n",
        "\n",
        "roc_curve_evaluation(y, y_pred, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnuhUyXMPzeg",
        "colab_type": "text"
      },
      "source": [
        "# **Original convolutional neural network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYJs6k-HQUwC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2 = Sequential()\n",
        "model_2.add(Convolution1D(100, 5, activation='relu', input_shape=(187, 1)))\n",
        "model_2.add(Convolution1D(110, 5, activation='relu'))\n",
        "model_2.add(Convolution1D(120, 5, activation='relu'))\n",
        "model_2.add(MaxPooling1D(3))\n",
        "model_2.add(Convolution1D(140, 10, activation='relu'))\n",
        "model_2.add(Convolution1D(150, 10, activation='relu'))\n",
        "model_2.add(Convolution1D(160, 10, activation='relu'))\n",
        "model_2.add(Convolution1D(170, 10, activation='relu'))\n",
        "model_2.add(Convolution1D(200, 10, activation='relu'))\n",
        "model_2.add(GlobalAveragePooling1D())\n",
        "model_2.add(Dropout(0.5))\n",
        "model_2.add(Dense(100, activation='relu'))\n",
        "model_2.add(Dense(50, activation='relu' ))\n",
        "model_2.add(Dense(2, activation='softmax'))\n",
        "\n",
        "print(model_2.summary())\n",
        "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLQ0QxsrQUsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_loss', patience=5)]\n",
        "\n",
        "history = model_2.fit(Xc_train, y_train, validation_data=(Xc_test, y_test), callbacks=callbacks, epochs=40, batch_size= 32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wnBt5iHQUo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = Xc_test\n",
        "y_test = y_test\n",
        "model = model_2\n",
        "model_evalutation(history, test, y_test, model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-7-UTihQUgI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model_2.predict(Xc_test, batch_size=1000)\n",
        "print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1)))\n",
        "\n",
        "# Compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plt.figure(figsize=(10, 10))\n",
        "plot_confusion_matrix(cnf_matrix, classes=['0','1'],\n",
        "                      title='Confusion matrix, without normalization')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXyxHAvQQoBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = y \n",
        "y_pred = model_2.predict(Xc_test, batch_size=1000)\n",
        "y_test = y_test\n",
        "\n",
        "roc_curve_evaluation(y, y_pred, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLrEcRF3Q2lB",
        "colab_type": "text"
      },
      "source": [
        "# **Well known convolutional neural network for comparison purposes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2p7WLlNRJP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_3 = Sequential()\n",
        "model_3.add(Convolution1D(6, 3, activation='relu', input_shape=(187, 1), padding='same'))\n",
        "model_3.add(AveragePooling1D(2))\n",
        "model_3.add(Convolution1D(16, 3, activation='relu', padding='valid'))\n",
        "model_3.add(AveragePooling1D(2))\n",
        "model_3.add(Flatten())\n",
        "model_3.add(Dense(120, activation='relu'))\n",
        "model_3.add(Dense(84, activation='relu'))\n",
        "model_3.add(Dense(2, activation='softmax'))\n",
        "\n",
        "print(model_3.summary())\n",
        "model_3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBeOAmX9ReSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_loss', patience=5)]\n",
        "\n",
        "history = model_3.fit(Xc_train, y_train, validation_data=(Xc_test, y_test), callbacks=callbacks , epochs=40, batch_size= 32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNcX_6z9RiFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = Xc_test\n",
        "model = model_3\n",
        "model_evalutation(history, test, y_test, model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TusAyBW_RkPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model_3.predict(Xc_test, batch_size=1000)\n",
        "print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1)))\n",
        "\n",
        "# Compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "np.set_printoptions(precision=2)\n",
        "# Plot non-normalized confusion matrix\n",
        "plt.figure(figsize=(10, 10))\n",
        "plot_confusion_matrix(cnf_matrix, classes=['0','1'],\n",
        "                      title='Confusion matrix, without normalization')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TW3djOVR19a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = y\n",
        "y_pred = model_3.predict(Xc_test, batch_size=1000)\n",
        "y_test = y_test\n",
        "\n",
        "roc_curve_evaluation(y, y_pred, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}